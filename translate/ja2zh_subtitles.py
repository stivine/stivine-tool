import os
import json
import tempfile
import argparse
import ffmpeg
import whisper
import pysrt
from tqdm import tqdm
from pathlib import Path

# ========== CONFIG ==========
MODEL_NAME = "small"           # Whisper æ¨¡å‹ (tiny, base, small, medium, large)
GPT_MODEL = "deepseek/deepseek-chat"      # æ”¯æŒ litellm çš„ä»»æ„æ¨¡å‹ï¼šgpt-4o-mini, claude-3-haiku, gemini/gemini-pro, ollama/llama3, etc.
LANG = "ja"                    # åŸå§‹è¯­éŸ³è¯­è¨€
OUTPUT_LANG = "zh"             # ç›®æ ‡è¯­è¨€
CACHE_DIR = ".cache"           # ç¼“å­˜ç›®å½•å
# ============================

# ä½¿ç”¨ litellm ä»£æ›¿ openai
import litellm
from litellm import completion


class VideoSubtitleGenerator:
    def __init__(self, api_key=None, api_base=None):
        self.api_key = api_key or os.getenv("API_KEY")  # å¯é€‚é…ä¸åŒå¹³å°çš„ KEY
        self.api_base = api_base or os.getenv("API_BASE")  # å¦‚ Ollama è‡ªå®šä¹‰åœ°å€
        if not self.api_key and GPT_MODEL.startswith("gpt"):
            raise ValueError("âŒ æœªæä¾› API Keyã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ API_KEY æˆ–é€šè¿‡ --api_key å‚æ•°ä¼ å…¥ã€‚")

        self.cache_dir = Path(CACHE_DIR)
        self.cache_dir.mkdir(exist_ok=True)

    def extract_audio(self, video_path, wav_path):
        """æå–éŸ³é¢‘ä¸ºå•å£°é“ 16kHz WAV"""
        print("ğŸ§ æ­£åœ¨æå–éŸ³é¢‘...")
        try:
            ffmpeg.input(video_path).output(
                wav_path, ac=1, ar=16000
            ).overwrite_output().run(quiet=True, capture_stdout=False, capture_stderr=False)
            print(f"âœ… éŸ³é¢‘å·²æå–è‡³: {wav_path}")
        except ffmpeg.Error as e:
            raise RuntimeError(f"éŸ³é¢‘æå–å¤±è´¥: {e.stderr.decode()}") from e

    def _seconds_to_srttime(self, seconds):
        """
        å°†æµ®ç‚¹ç§’æ•°è½¬æ¢ä¸º pysrt.SubRipTime å¯¹è±¡
        å…¼å®¹ä¸æ”¯æŒ from_seconds() çš„ pysrt ç‰ˆæœ¬
        """
        ms = int((seconds - int(seconds)) * 1000)
        total_seconds = int(seconds)
        hours, rem = divmod(total_seconds, 3600)
        minutes, seconds = divmod(rem, 60)
        return pysrt.SubRipTime(hours, minutes, seconds, ms)

    def transcribe_with_cache(self, audio_path, cache_key):
        """ä½¿ç”¨ç¼“å­˜è¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        cache_file = self.cache_dir / f"{cache_key}_transcribe.json"
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨
        if cache_file.exists():
            print("ğŸ” æ£€æµ‹åˆ°è½¬å½•ç¼“å­˜ï¼Œæ­£åœ¨åŠ è½½...")
            with open(cache_file, "r", encoding="utf-8") as f:
                segments = json.load(f)
            print("âœ… è½¬å½•ç¼“å­˜åŠ è½½å®Œæˆ")
        else:
            print("ğŸ§  ä½¿ç”¨ Whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«...")
            if not hasattr(self, 'whisper_model') or self.whisper_model is None:
                self.whisper_model = whisper.load_model(MODEL_NAME)

            result = self.whisper_model.transcribe(audio_path, language=LANG, verbose=False)
            segments = result["segments"]

            # ä¿å­˜ç¼“å­˜
            with open(cache_file, "w", encoding="utf-8") as f:
                json.dump(segments, f, ensure_ascii=False, indent=2)
            print("âœ… è½¬å½•å®Œæˆå¹¶å·²ç¼“å­˜")

        # è½¬æ¢ä¸º pysrt å­—å¹•å¯¹è±¡
        subs = pysrt.SubRipFile()
        for i, seg in enumerate(segments):
            start = self._seconds_to_srttime(seg["start"])
            end = self._seconds_to_srttime(seg["end"])
            text = seg["text"].strip()
            subs.append(pysrt.SubRipItem(index=i+1, start=start, end=end, text=text))
        return subs

    def translate_with_cache(self, subs, cache_key):
        """ä½¿ç”¨ litellm è¿›è¡Œç¿»è¯‘ï¼Œæ”¯æŒå¤šç§æ¨¡å‹ + æ–­ç‚¹ç»­ä¼ """
        cache_file = self.cache_dir / f"{cache_key}_translate.json"
        translated_subs = pysrt.SubRipFile()

        # å°è¯•åŠ è½½å·²æœ‰ç¿»è¯‘ç¼“å­˜
        cache_data = {}
        if cache_file.exists():
            try:
                with open(cache_file, "r", encoding="utf-8") as f:
                    cache_data = json.load(f)
                print(f"ğŸ” æ£€æµ‹åˆ°ç¿»è¯‘ç¼“å­˜ï¼Œå·²æ¢å¤ {len(cache_data)} æ¡ç¿»è¯‘è®°å½•")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è¯»å–ç¿»è¯‘ç¼“å­˜: {e}")

        # è®¾ç½® litellm å…¨å±€å‚æ•°ï¼ˆå¯é€‰ï¼‰
        litellm.drop_params = True  # å…è®¸ä¼ å…¥ä½†æ¨¡å‹ä¸æ”¯æŒçš„å‚æ•°è‡ªåŠ¨å¿½ç•¥
        litellm.telemetry = False  # å…³é—­é¥æµ‹

        # é€æ¡ç¿»è¯‘
        for sub in tqdm(subs, desc="ğŸŒ ç¿»è¯‘è¿›åº¦"):
            key = str(sub.index)
            if key in cache_data and cache_data[key].strip():
                zh_text = cache_data[key]
                translated_subs.append(
                    pysrt.SubRipItem(index=sub.index, start=sub.start, end=sub.end, text=zh_text)
                )
                continue

            # æ„å»ºæç¤ºè¯
            prompt = f"è¯·å°†ä»¥ä¸‹æ—¥è¯­å­—å¹•è‡ªç„¶æµç•…åœ°ç¿»è¯‘æˆç®€ä½“ä¸­æ–‡å­—å¹•ï¼Œä¸è¦è§£é‡Šï¼Œä¸è¦ä¿ç•™æ—¥è¯­ï¼Œä¸è¦æ·»åŠ é¢å¤–å†…å®¹ï¼š\n\n{sub.text}"

            try:
                response = completion(
                    model=GPT_MODEL,  # å¦‚ "gpt-4o-mini", "claude-3-haiku", "gemini/gemini-pro", "ollama/llama3"
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3,
                    api_key=self.api_key,
                    api_base=self.api_base  # æ”¯æŒè‡ªå®šä¹‰ç«¯ç‚¹ï¼ˆå¦‚ Ollamaï¼‰
                )
                zh_text = response.choices[0].message['content'].strip()
            except Exception as e:
                print(f"\nâš ï¸ ç¬¬ {sub.index} å¥ç¿»è¯‘å¤±è´¥: {e}")
                zh_text = f"[ç¿»è¯‘å¤±è´¥: {str(e)}]"

            # æ›´æ–°ç¼“å­˜å’Œå­—å¹•
            cache_data[key] = zh_text
            translated_subs.append(
                pysrt.SubRipItem(index=sub.index, start=sub.start, end=sub.end, text=zh_text)
            )

            # å®æ—¶ä¿å­˜ç¼“å­˜ï¼Œé˜²æ­¢ä¸­æ–­
            with open(cache_file, "w", encoding="utf-8") as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)

        print("âœ… ç¿»è¯‘å®Œæˆ")
        return translated_subs

    def generate_subtitles(self, video_path, output_srt):
        video_path = Path(video_path).resolve()
        if not video_path.exists():
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

        cache_key = video_path.stem

        with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as tmp_wav:
            wav_path = tmp_wav.name

            # 1. æå–éŸ³é¢‘
            self.extract_audio(str(video_path), wav_path)

            # 2. è½¬å½•
            subs_ja = self.transcribe_with_cache(wav_path, cache_key)

            # 3. ç¿»è¯‘ï¼ˆä½¿ç”¨ litellmï¼‰
            subs_zh = self.translate_with_cache(subs_ja, cache_key)

            # 4. ä¿å­˜å­—å¹•
            subs_zh.save(output_srt, encoding="utf-8")
            print(f"âœ… ä¸­æ–‡å­—å¹•å·²ä¿å­˜: {output_srt}")


def main():
    parser = argparse.ArgumentParser(description="ğŸ¬ æ—¥è¯­è§†é¢‘ â†’ ä¸­æ–‡å­—å¹•è‡ªåŠ¨ç”Ÿæˆï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œä½¿ç”¨ litellm å¤šæ¨¡å‹ï¼‰")
    parser.add_argument("video", help="è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚: video.mp4ï¼‰")
    parser.add_argument("--api_key", help="API Keyï¼ˆå¦‚ OpenAIã€Anthropicã€Gemini ç­‰ï¼‰")
    parser.add_argument("--api_base", help="API Base URLï¼ˆå¦‚ Ollama åœ°å€: http://localhost:11434ï¼‰")
    parser.add_argument("--output", default="subs_zh.srt", help="è¾“å‡ºå­—å¹•æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: subs_zh.srtï¼‰")

    args = parser.parse_args()

    try:
        generator = VideoSubtitleGenerator(api_key=args.api_key, api_base=args.api_base)
        generator.generate_subtitles(args.video, args.output)
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        exit(1)


if __name__ == "__main__":
    main()